<!doctype html>
<html lang="en">

<head>
  <meta charset="utf-8">

  <title>A Practical Guide to Applied Machine Learning</title>

  <meta name="description" content="Using python and scikit-learn, we'll walk through a machine learning process from start to finish discussing when to apply machine learning, the most successful algorithms, best practices, and even a little philosophy.">
  <meta name="author" content="Jeremy Gore">

  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent" />

  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no, minimal-ui">

  <link rel="stylesheet" href="reveal.js/css/reveal.css">
  <link rel="stylesheet" href="css/tessella.css" id="theme">
  <link rel="stylesheet" href="css/presentation.css">

  <!-- Code syntax highlighting -->
  <link rel="stylesheet" href="reveal.js/lib/css/zenburn.css">

  <!-- Printing and PDF exports -->
  <script>
    var link = document.createElement('link');
    link.rel = 'stylesheet';
    link.type = 'text/css';
    window.printing_pdf = window.location.search.match(/print-pdf/gi);
    link.href = window.printing_pdf ? 'reveal.js/css/print/pdf.css' : 'reveal.js/css/print/paper.css';
    document.getElementsByTagName('head')[0].appendChild(link);
  </script>

<!--[if lt IE 9]>
<script src="lib/js/html5shiv.js"></script>
<![endif]-->
</head>

<body>
<div class="reveal">
<div class="slides">

<section>
  <section id="title">
    <div class="tier">
      <svg width="300" height="600"></svg>
      <div class="w2 text-right">
        <img class="noborder" style="width:300px;height:auto; margin-bottom:1em; " src='img/Tessella_Logo.png'>
        <h2 class="text-right">A Practical Guide to Applied Machine Learning</h2>
        <h2 class="text-right"><small>Jeremy Gore<br>Autumn Conference 2015-10-05</small></h2>
      </div>
    </div>

    <aside class="notes" data-markdown>
      To say machine learning is a big subject is a big understatement, but it may be easier than you think.

    </aside>
  </section>

  <section id="instructions" data-background="#996699" data-background-transition="zoom">
    <h3>Presentation instructions</h3>
    <ul>
      <li>Press <kbd>ESC</kbd> to enter the slide overview</li>
      <li>Press <kbd>F</kbd> to display full screen</li>
      <li>Press <kbd>B</kbd> or <kbd>.</kbd> to pause the presentation</li>
      <li>Press <kbd>S</kbd> to display the speaker view with notes</li>
      <li><kbd>Alt+click</kbd> on any element to zoom in on it, <kbd>Alt+click</kbd> anywhere to zoom back out</li>
      <li><kbd>Swipe</kbd> to move on mobile devices</li>
    </ul>
  </section>
</section>

<section id="topics">
  <h2>Topics</h2>
  <div class="tier">
    <ul class="boxed green">
      <h4 class="heading">Will Cover</h4>
      <li>What is ML</li>
      <li>Job process</li>
      <li>Python with scikit-learn</li>
      <li>Major supervised algorithms</li>
    </ul>
    <ul class="boxed red">
      <h4 class="heading">Won't Cover</h4>
      <li>Other algorithms</li>
      <li>Other Platforms</li>
      <li>Structured and sequential data models</li>
    </ul>
  </div>

  <aside class="notes" data-markdown>
    So today we are going to walk through the machine learning process from start to finish.  We will discuss what machine learning is, when to apply it, and what you need to do to guarantee good results.  We will be doing so in the context of one of the most popular machine learning platforms, Python with scikit-learn.  Along the way we'll cover some of the most successful supervised learning algorithms.

    We *won't* be covering other algorithms, other ml platforms, or more complex data models, but rest assured much of what we will discuss today can be applied directly in these other contexts.

    So, let's get started.
  </aside>
</section>

<section>
  <section id="what-is-ml">
    <h1>What is machine learning?</h1>
    <img class="noborder" src="img/ml.gif">

    <aside class="notes" data-markdown>
      So then, what *is* machine learning? Fundamentally, it's a way of producing a model that explains your data.  But instead of a human generating that model based upon data and experiment, it is the machine which is learning the model, usually from the data alone, and without preconceived notions about how that model should be structured.

      Well that sounds great!  The machine is doing all the work!  Well, not quite.  There is still a lot for you to do, as you shall soon see.
    </aside>
  </section>

  <section id="concepts">
    <h2>Core Concepts</h2>
    <img class="noborder" src="img/concepts.svg">
    <blockquote>Modeling is Abstraction</blockquote>

    <aside class="notes" data-markdown>
      Let's start with the basics.  Like any discipline machine learning has some key concepts which you need to be familiar with.  We will explain these terms in more detail in the rest of the presentation, but I want you to keep them in mind as we do:

      Machine learning is a form of *Modeling*, which is to say that it is an abstraction of **Data**, which is made up of individual **Items** or equivalently **Records**, **Points**, or **Samples**. **Features** are the various numerical and categorical traits which describe the item, and **Labels** are what you are attempting to predict based on the features.  **Classes** are the discrete possible values which labels may take in classification problems.

      **Models** are the tools you use to explain your samples.  In machine learning, models are built on, and generated by, **Algorithms**.  ML models can have radically different designs but all are intended to learn complex representations of arbitrary data.  The tunable parts of a model are called **Parameters**, and there are also **Hyperparameters** which control how the model is constructed and trained.
    </aside>
  </section>

  <section id="hardware-software">
    <h2>Hardware and Software</h2>
    <div class="tier">
      <ul class="boxed orange">
        <h4 class="heading">Machine</h4>
        <li>Plenty of memory (8GB)</li>
        <li>NVidia GPU, or decent CPU</li>
        <li>Preferably Linux</li>
        <li>Local or Server?</li>
      </ul>
      <ul class="boxed purple">
        <h4 class="heading">ML Platform</h4>
        <li><a href="https://www.r-project.org/">R</a></strong>: Premier statistical platform</li>
        <li><a href="https://www.python.org/">Python</a></strong>: Production ready, highly flexible</li>
        <li><em><a href="http://www.mathworks.com/products/matlab/">MatLab</a></em>: Proprietary numerical platform</li>
        <li><em><a href="http://julialang.org/">Julia</a></em>: New hotness</li>
      </ul>
    </div>

    <aside class="notes" data-markdown>
      Like any heavy computing task, in machine learning you must consider hardware and software.

      When choosing the system to perform machine learning (if you have a choice) you should take the following aspects into account:

      1. Plenty of memory, because both datasets and algorithms can require a lot of memory
      2. NVidia GPU, because the libraries that use those can give massive performance improvements for neural networks, often 30x.  It can make a huge difference in your ability to investigate.  Failing that, you want the best CPU you can get.
      3. Most tools, libraries, and dependencies are available for Linux, OS X, and Windows.  But you will find that actually installing those on systems other than Linux can be quite painful, even on another Unix like OS X.  One time I had a compile fail because I didn't invoke the makefile from bash.  So if you can, save yourself some grief and use Linux.
      4. The first three requirements definitely favor a server, but there are plenty of benefits to being able to work without a connection.  If you can, do both, and keep things in sync with git, which you were already using RIGHT?

      Which brings us to your machine learning software platform.  Sure there are innumerable tools and services, but if you want to investigate properly you need a platform with a consistent interface which is kept up-to-date with the latest algorithms. At the moment, there are two primary ones and two secondary ones, all of which I have used at one time or another.

      [R](https://www.r-project.org/) is *the* premier open source statistical platform, and the most popular ML tool with the most algorithms.  It is widely used in academia, and so most new algorithms actually show up there first.

      [Python](https://www.python.org/) on the other hand is a general-purpose programming language which has some nice packages for machine learning.  Significantly, python is production ready and excellent for data wrangling.  This is the environment I will be using today.

      The other two are of more limited interest.  [MatLab](http://www.mathworks.com/products/matlab/) is a numerical computing environment with extensive use in academic and research institutions. But it is also proprietary and expensive and doesn't see much use elsewhere. [Julia](http://julialang.org/) is a very new high-performance dynamic programming language. It is very interesting but still very much in development, so I can't recommend it just yet.
    </aside>
  </section>

  <section id="py-ml-stack">
    <h2>Recommended Python ML Stack</h2>
    <div class="tier">
      <ul class="boxed">
        <li>Python</li>
        <li>Pandas</li>
        <li>scikit-learn</li>
        <li>scikit-neuralnetwork</li>
        <li>Theano</li>
      </ul>
      <div class="w2">
        <img class="noborder" width="300" height="150" src="img/logo-anaconda.svg">
        <p><a href="https://www.continuum.io/">https://www.continuum.io/</a></p>
        <blockquote>You must install a compiler (g++) and ideally CUDA</blockquote>
<pre><code class="sh" data-trim>
$ conda install mingw libpython
$ pip install theano scikit-neuralnetwork
</code></pre>
      </div>
    </div>

    <aside class="notes" data-markdown>
      To handle the code I am going to show you today you will need to install the following software:

      - Python
      - Pandas for data io
      - scikit-learn for most machine learning algorithms
      - and scikit-neuralnetwork with Theano for neural networks

      You could install those individually, but I would recommend that you use the Anaconda distribution for scientific python, and then install theano and scikit-neuralnetwork using the pip package manager. Also, theano requires a compiler, so you will need to install that if you don't already have it.  And ideally, if you have a compatible NVIDIA GPU you can install their CUDA tools for even faster execution.  It is well worth it but installation can be a bit of a pain.
    </aside>
  </section>

</section>

<section>
  <section id="steps">
    <h1>The steps of a machine learning job</h1>
    <ol>
      <li>Know your problem</li>
      <li>Prepare your data</li>
      <li>Set up your test harness</li>
      <li>Spot check a variety of algorithms</li>
      <li>Fine tune your best models</li>
    </ol>

    <aside class="notes" data-markdown>
      Machine learning isn't just algorithms.  There is a definite process to it, and applying the algorithms is in many ways the least complex part of it.  Let's take a look at the steps of the problem.
    </aside>
  </section>

</section>

<section>
  <section id="problem">
    <h1 class="text-left">1. Know your problem</h1>
    <div class="tier vc">
      <div class="w2">
        <ul>
          <li>What problem are you trying to solve?</li>
          <li>Is machine learning the right choice?</li>
          <li>What kind of machine learning is warranted?</li>
          <li>How will you judge model performance?</li>
        </ul>
      </div>
      <div>
        <img src="img/thinking.png">
      </div>
    </div>

    <aside class="notes" data-markdown>
      The most fundamental question for machine learning (or indeed most projects) is what problem are you trying to solve? Can machine learning help you with this, and what class of learning is required?  How will you judge your model's performance?
    </aside>
  </section>

  <section id="when-ml">
    <h2>When to use machine learning</h1>
    <img class="noborder" src="img/celebs.jpg">
    <blockquote>Machine learning is appropriate when the problem is too dynamic or complex to be handled by simple rules or models</blockquote>

    <aside class="notes" data-markdown>
      Let's start with when to use Machine Learning.  Machine learning is most useful on tasks which can be solved but not simply explained.  For instance, consider facial recognition.  As a human being you can do this easily, but I doubt you can describe just how you do it.  Even if you could, it would be a complex and inelegant explanation.  This applies to facial recognition algorithms as well.  People tried writing these by hand originally but their accuracy was mediocre at best.  The latest machine learning algorithms are far more accurate than anything developed by hand.

      So when shouldn't you use machine learning? Machine learning models can solve a lot of problems but many algorithms don't offer much insight into the nature of those problems.  In other words, they can get you a result even if they don't give you an explanation.  That may not be enough.  Also, machine learning is not magic, it is limited by the quality of the data and by its own design.  So it's not going to work for every data set.
    </aside>
  </section>

  <section id="ml-flavors">
    <h2>Flavors of Machine Learning</h2>
    <div class="tier">
      <ul class="boxed red">
        <h4 class="heading">Supervised</h4>
        <li>Classification</li>
        <li>Regression</li>
        <li>Ranking</li>
      </ul>
      <ul class="boxed blue">
        <h4 class="heading">Unsupervised</h4>
        <li>Clustering</li>
        <li>Density estimation</li>
        <li>Pattern identification</li>
        <li>Representation learning</li>
      </ul>
      <ul class="boxed green">
        <h4 class="heading">Other</h4>
        <li>Semi-supervised</li>
        <li>Reinforcement learning</li>
      </ul>
    </div>

    <aside class="notes" data-markdown>
      There are two major types of machine learning.  Supervised learning is the prediction of a label based on the input features.  It is used for classifying samples, regression to a numerical amount, or ranking.  Unsupervised learning is identifying structure in the input data.  This include clustering, density estimation, pattern identification, and so on.  Fundamentally every form of unsupervised technique is a way of representing the original data, i.e. compression.

      Besides the big two there are others, such as semi-supervised learning in which not all training data is labeled, and reinforcement learning which can be used for training robots without explicit instructions.
    </aside>
  </section>

  <section id="data-models">
    <h2>Data and models</h2>

    <div class="tier">
      <div>
        <img class="noborder" src="img/titanic.png" height="250px" width="auto">
      </div>
      <div>
        <img class="noborder" src="img/convolution.jpg" height="250px" width="auto">
      </div>
    </div>
    <div class="row">
      <div>
        <img class="noborder" src="img/diags.jpeg" height="250px" width="auto">
      </div>
    </div>

    <aside class="notes" data-markdown>
      The exact form your problem will take is closely related to the form of your data.  In plain tabular data the features of the sample are not really related to each other.  But this is not always the case.  Others require special formulation and considerations.  Images for instance are a form of structured data.  It's features are pixels, but ever pixel is similar to the others and has relationships with neighboring pixels.  Other models, such as text and video, have a temporal component.  Taking these qualities into account is necessary when choosing your models.
    </aside>
  </section>

</section>

<section>
  <section id="data">
    <h1 class="text-left">2. Prepare your data</h1>
    <div class="tier vc">
      <div>
        <img class="noborder" src="img/data.jpg">
      </div>
      <ul class="w2">
        <li>Where is it, how can I get it, and am I allowed to use it?</li>
        <li>What form is it in, and how do I convert it to a form that can be analyzed?</li>
        <li>What does it look like?</li>
        <li>Is it any good and do you have enough of it?</li>
      </ul>
    </div>

    <aside class="notes" data-markdown>
      The next major step is to prepare your data.  You have to obtain it, you have to understand it, and you need to prepare to work with it.  Let's look at those major steps.
    </aside>
  </section>

  <section id="wrangling">
    <h2>Data Wrangling</h2>
    <div class="tier">
      <ul class="boxed purple">
        <li>Get it</li>
        <li>Convert to useful format</li>
        <li>Handle blanks</li>
        <li>Convert categorical features to numeric</li>
        <li>Remove unhelpful features</li>
        <li>Add helpful features</li>
      </ul>
      <div>
        <img src="img/wrangling.gif">
        <blockquote>It's 90% of the job.</blockquote>
      </div>
    </div>
    <aside class="notes" data-markdown>
      Data wrangling (or munging or preparation) is the process of preparing your data for analysis.  That doesn't sound like much, but in fact it is the most tedious and time consuming part of the entire process.  You will spend 90% of a machine learning job just whipping your data into shape, and what you need to do will be different every time.  I'm not even going to describe it in detail.  But at minimum, you will need to: get the data; convert it into a format you can work with; figure out what to do with blanks or placeholder values; convert categorical features to a numeric form; remove unhelpful features; and add helpful ones from other sources.

      The good news is, you work for Tessella, which means you have done or will soon do this sort of thing many times.
    </aside>
  </section>

  <section id="pandas">
    <h2>Data i/o with Pandas</h2>
<pre><code class="py" data-trim data-noescape>
import pandas as pd

# Reading the data from a csv file
df = pd.read_csv("input/data.csv");

# Write out data later...
predict_df = pd.DataFrame({'Id': ids, 'Label': predictions })
predict_df.to_csv("output/predict.csv")

# Convert categorical column to one-hot dummy columns
df = pd.concat([df, pd.get_dummies(
  df[cat_colname], prefix=cat_colname)], axis=1)

# Get features matrix 'X' for feature names (don't include ID!)
X = df[feature_colnames].values

# Get labels vector 'y'
y = df[label_colname].values

</code></pre>
    <aside class="notes" data-markdown>
      Somewhere in the data wrangling process you will need to load your data for analysis (and maybe wrangle it some more).  And at the end of the job you will need to output it.  With tabular data, the pandas library is a great help.  This is essentially the dataframes object that is popular in R.  It has many functions including file i/o, conversion of categorical columns to one-hot dummy forms, and extraction of subtables.  For the full functionality I suggest checking out a tutorial.
    </aside>
  </section>

  <section id="exploration">
    <h2>Data Exploration</h2>
    <div class="tier">
      <div>
<pre><code class="py" data-trim data-noescape>
# See first few rows
df.head()

# Shows basic statistics for all
#  numeric columns
df.describe()

# See histograms for columns
df.hist()

# Determine balance of classes
print df[label_name].value_counts()
>>> 0    500
>>> 1    268
>>> dtype: int64
</code></pre>
      </div>
      <div>
        <table border="1" class="dataframe">
          <thead>
            <tr style="text-align: right;">
              <th></th>
              <th>preg</th>
              <th>plas</th>
              <th>pres</th>
              <th>age</th>
              <th>class</th>
            </tr>
          </thead>
          <tbody>
            <tr>
              <th>0</th>
              <td>6</td>
              <td>148</td>
              <td>72</td>
              <td>50</td>
              <td>1</td>
            </tr>
            <tr>
              <th>1</th>
              <td>1</td>
              <td>85</td>
              <td>66</td>
              <td>31</td>
              <td>0</td>
            </tr>
            <tr>
              <th>2</th>
              <td>8</td>
              <td>183</td>
              <td>64</td>
              <td>32</td>
              <td>1</td>
            </tr>
            <tr>
              <th>3</th>
              <td>1</td>
              <td>89</td>
              <td>66</td>
              <td>21</td>
              <td>0</td>
            </tr>
            <tr>
              <th>4</th>
              <td>0</td>
              <td>137</td>
              <td>40</td>
              <td>33</td>
              <td>1</td>
            </tr>
          </tbody>
        </table>
        <img class="noborder" src="img/histograms.png">
      </div>
    </div>
    <aside class="notes" data-markdown>
      Before you try applying machine learning, you should always look at your data directly to get a feel for what you are working with.  More generally you need to know if your data is any good and if you have enough to effectively learn from it. Just like in statistics, bad data is worse than no data.

      Pandas is helpful here.  To start with, just look at the first few rows with head.  This can tell you quite a bit. You can also use describe to see basic statistics.  The hist method is a particularly useful way to quickly see if any of your columns have non-normal distributions.

      For non-numeric columns, you can use the value_counts method to see what the distribution of values is.  You should always do this for classification problems to ensure that they are reasonably balanced.  Because if 99% of your samples are in class A, then you can score 99% accuracy just by always guessing class A.  If your classes are seriously imbalanced, you will need to address this when you build your models.
    </aside>
  </section>

  <section id="dimensionality">
    <h2>The curse of dimensionality</h2>
    <blockquote>The more dimensions you have, the more volume you have to cover</blockquote>
    <img class="noborder" width="auto" height="250px" src="img/dimensionality.png">
    <blockquote>Consider reducing your features</blockquote>
<pre><code class="py" data-trim data-noescape>
from sklearn.decomposition import PCA
from sklearn.ensemble import RandomForestClassifier
</code></pre>
    <aside class="notes" data-markdown>
      Irrelevant features are for all intents and purposes noise in your data.  They increase the risk of spurious correlations, make most algorithms less efficient, and lead to higher memory consumption.  But there are deeper issues as well.  What happens is that every dimension you add increases the volume of the bounded space exponentially.  That means you will also need exponentially more training data in order to describe that space sufficiently for your model to learn.  The moral of the story is, you should consider reducing your features, particularly if your data has a large number of them.

      There are many ways to reduce dimensions but two in particular stand out.  If the identities of your features are not important than you may want to project into a lower dimensional space with PCA.  Otherwise, you probably want to estimate feature importances with a RandomForest and keep the important ones.
    </aside>
  </section>

</section>

<section>
  <section id="harness">
    <h1 class="text-left">3. Set up your harness</h1>
    <div class="tier vc">
      <ul>
        <li>Set up your project directory</li>
        <li>Clean up your data into a form suitable for analysis</li>
        <li>Verify the scoring measure to use</li>
        <li>Set up your analysis routines</li>
      </ul>
      <div>
        <img class="noborder" src="img/organize.jpg">
      </div>
    </div>


    <aside class="notes" data-markdown>
      Now that you understand the problem and your data, it's time to prepare to make predictions.  You'll need to set up your test harness.  First set up your work directory, then get your data into a form suitable for loading as we described previously.  Select the scoring measure you wish to use, and then set up all the routines you need for analysis.  When you are done you should be ready to run.
    </aside>
  </section>

  <section id="train-test-predict">
    <h2>Standard train-test-predict workflow</h2>
<pre><code class="py" data-trim data-noescape>
from sklearn.ensemble import ExtraTreesClassifier

# Create a model
clf = ExtraTreesClassifier(n_estimators:1024, class_weight:"subsample")

# Fit the model
clf.fit(X_train, y_train)

# Verify performance
print clf.score(X_test, y_test)
>>> 0.82

# To make predictions
y_predict = clf.predict(X_predict)
</code></pre>

    <aside class="notes" data-markdown>
      So here is a typical example of training and testing models, and as you can see it is quite straightforward.  The nicest thing about scikit-learn is the consistency of their approach.  All methods, parameter names, and parameter values will have the same names to the greatest extent possible.  This means you can pick and choose your algorithms without having to write a lot of glue code.

      Here I am creating a new classifier with some designated parameters (really these are hyperparameters) using the constructor, and `fit` it to the features and labels.  Then I verify the performance on my validation set using `score`. If I am satisfied with the result, all I need to do to make predictions is call `predict`.
    </aside>
  </section>

  <section id="splitting">
    <h2>Splitting data for validation</h2>
<pre><code class="py" data-trim data-noescape>
from sklearn.cross_validation import train_test_split,
  KFold, StratifiedShuffleSplit

# Quickly split into 80% train and 20% test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)

# Or generate 5 random splits preserving class percentages
sss = StratifiedShuffleSplit(y, 5, test_size=0.2)
for i_train, i_test in folds:
  X_train, X_test = X[i_train], X[i_test]
  y_train, y_test = y[i_train], y[i_test]

# Or split into 5 folds, etc.
folds = KFold(y.length, 5, shuffle=True)
</code></pre>
<img class="noborder" src="img/kfold.gif">
    <aside class="notes" data-markdown>
      We don't jump straight from data to modelling.  We will need to evaluate many models.  And that means we need ways of validating those models and comparing them.  We can test the accuracy of a model on the training data, but if that model is overfitting the data the score is going to be misleadingly high.  That's why we also need the score for data that we didn't train with, which means we will need to set aside some of our data.  Once we are satisfied with a model's performance, we can create a new model with the same recipe and all the data for maximum accuracy.

      The simplest way to split your data in Python is with the train_test_split function, which will randomly split all input matrices the same way.  I personally favor an 80-20 split.

      Of course one train-test split may by chance not produce representative results, so you usually want to split more than once.  There are many different strategies, but they all work the same: create a splitter and get back a series of tuples with the train and test indices, test with each train/test split, and average the results.
    </aside>
  </section>

  <section id="preprocess-pipeline">
    <h2>Preprocessing and Pipelines</h2>
    <div class="tier vc">
      <div class="w2">
<pre><code class="py" data-trim data-noescape>
from sklearn.preprocessing import StandardScaler
from sklearn.pipeline import Pipeline
from sklearn.svm import SVC

# We could preprocess like this:
ss = StandardScaler()
X_train_prep = ss.fit_transform(X_train)
X_test_prep = ss.transform(X_test)
clf = SVC(kernel="rbf", class_weight="auto");
clf.fit(X_train_prep, y_train)

# Or we could simplify with a pipeline
clf = Pipeline([
  ('ss', StandardScaler()),
  ("svc", SVC(kernel="rbf"))])

# You can even set parameters on it
clf.set_params(svc__class_weight="auto")

clf.fit(X_train, y_train)
</code></pre>
      </div>
      <div>
        <p>
          $$\begin{align}
          X' =& \frac{X - \mu}{\sigma}\\
          \\
          X' =& \frac{X - X_{min}}{X_{max} - X_{min}}\\
          \end{align}$$
        </p>
      </div>
    </div>
    <aside class="notes" data-markdown>
      If we are using a classifier which needs preprocessing (which is most of them) then there are a couple of ways to do that.

      You could do it the obvious way and do all the steps separately.  Or you could do it the easy way, and wrap your preprocessors and main classifier into a pipeline.  The resulting Pipeline objects behaves exactly like any other scikit-learn model.  You can even set parameters on it, because we named all of the parts of the pipeline.
    </aside>
  </section>

</section>

<section>
  <section id="spot-check">
    <h1 class="text-left">4. Spot check a variety of algorithms</h1>
    <img class="noborder" src="img/algorithms.png">
    <aside class="notes" data-markdown>
      Once you have everything set up, it's time to move to the next phase - building a model.  To do that, you are actually going to need to test a variety of algorithms to find one that is going to work well for your problem and data.  And that begins by spot checking a range of algorithms.
    </aside>
  </section>

  <section id="model-generator">
    <h2>Standard algorithm generator</h2>
    <blockquote>I recommend setting up a reusable generator of starter models</blockquote>
<pre><code class="py" data-trim data-noescape>
def standard_clfs():
  yield ExtraTreesClassifier(n_estimators=256)
  yield Pipeline([
    ('feat', RandomForestClassifier(max_depth=3,
      n_estimators=64, class_weight="auto")),
    ('et', ExtraTreesClassifier(n_estimators=256))])
  yield Pipeline([
    ('scale', StandardScaler()),
    ('svc', SVC())])

for clf in standard_clfs():
  print clf.fit(X_train, y_train).score(X_test, y_test)
</code></pre>
    <aside class="notes" data-markdown>
      I'd like to make a recommendation for how you go about doing this: set up a standard list of preconfigured models to evaluate, and the code to evaluate them quickly.  In python, the natural approach is to use a generator to stream the models to test.  That way you are consistent, and you can let your code spot-check your models while you do something else.  When it's done you can review the results and pick which models to examine further.

      But there are of course many many different algorithms with an infinite number of configurations.  So which ones should you test?
    </aside>
  </section>

  <section id="no-free-lunch">
    <h2>No Free Lunch Theorem</h2>
    <p>No one algorithm will be suitable for all problems and any algorithm could be the right one.<span class="fragment" data-fragment-index="1">.. <i>but in practice only a handful of algorithms are really worth considering.</i></span></p>

    <div class="tier fragment" data-fragment-index="2">
      <div class="well">
        <h4>Random Forests</h4>
      </div>
      <div class="well">
        <h4>Neural Networks</h4>
      </div>
    </div>
    <div class="tier fragment" data-fragment-index="2">
      <div class="well">
        <h4>Support Vector Machines</h4>
      </div>
      <div class="well">
        <h4>Cheap Algorithms</h4>
      </div>
    </div>

    <aside class="notes" data-markdown>
      There is something called the no-free-lunch theorem, which basically says no one algorithm will be suitable for all problems and that any algorithm could be the right one.  Which isn't particularly helpful.

      *But* in practice some algorithms are definitely more useful than others.  In fact there's only a handful that are really good.  And here they are: Random Forests and Neural Networks are definitely the big two.  Support Vector Machines are also good enough to be worth a shot, and there's no reason not to try various cheap algorithms.

      Let's look at these.
    </aside>
  </section>

  <section id="decision-tree">
    <div class="tier vc">
      <div>
        <h2 class="text-left">Decision trees</h2>
        <ul class="boxed green stretch small">
          <li>Easily understood</li>
          <li>No preprocessing</li>
          <li>Fast and cheap</li>
        </ul>
        <ul class="boxed red stretch small">
          <li>Overfits</li>
          <li>No mathematical processing</li>
        </ul>
      </div>
      <svg width="400" height="500"></svg>
    </div>
<pre><code class="py" data-trim data-noescape>
from sklearn.tree import
  DecisionTreeClassifier, DecisionTreeRegressor
</code></pre>
    <aside class="notes" data-markdown>
      Algorithms can categorized by how they work with input data.  One way of doing that is using decision trees.

      Decision trees are arguably the simplest and most intuitive machine learning model in existence.  They are essentially a flowchart: for each node starting at the root, you evaluate a rule and are directed to another node, until you reach a final decision. They require no preprocessing and are fast and cheap to train, store, and evaluate.

      How you actually build a given decision tree from the training data depends on your algorithm. With a simple algorithm and no constraints they can produce the best possible fit to the training data.  Which is to say, they can easily overfit.  Also, they can't perform any mathematical processing, so they do not generalize very well.

      But it's a different story if you use more than one...
    </aside>
  </section>

  <section id="random-forest">
    <div class="tier vc">
      <svg width="450" height="500"></svg>
      <div>
        <h2 class="text-left">Random Forests</h2>
        <ul class="boxed green stretch small">
          <li>No preprocessing</li>
          <li>Minimal tuning</li>
          <li>Fast</li>
          <li><a href="http://jmlr.csail.mit.edu/papers/volume15/delgado14a/delgado14a.pdf">Reliably good results</a></li>
        </ul>
        <ul class="boxed red stretch small">
          <li>No mathematical processing</li>
        </ul>
      </div>
    </div>
<pre><code class="py" data-trim data-noescape>
from sklearn.ensemble import
  RandomForestClassifier, RandomForestRegressor,
  ExtraTreesClassifier, ExtraTreesRegressor
</code></pre>
    <aside class="notes" data-markdown>
      A random forest is just an ensemble of specially constructed decision trees.  Each tree is different because at any given branch it can only choose from a random set of features - or a random set of feature splits in the case of the extra trees variant.

      Random forests have several really nice practical aspects:

      - Since they are based on decision trees, no preprocessing of features is necessary.
      - There are few hyperparameters to tune and those hyperparameters are very forgiving.
      - Training and evaluation is typically quite fast.  You can add trees for accuracy or remove trees for performance at will.
      - Most importantly random forests work [very well on a very large number of problems](http://jmlr.csail.mit.edu/papers/volume15/delgado14a/delgado14a.pdf).

      In fact if I was really in a pinch and could use only one algorithm, it would be ExtraTrees.  It will almost certainly give me an accurate result with little to no fuss whatsoever.

      Forests work well because [bagging is most effective on unstable algorithms that overfit easily](http://statistics.berkeley.edu/sites/default/files/tech-reports/421.pdf)... and decision trees overfit more easily than just about anything.
    </aside>
  </section>

  <section id="linear-transformation">
    <h2>Linear Transformations</h2>
    <div class="tier vc" style="align-items:center;">
      <div style="padding:20px">
        <p>
          $$\begin{align}
          s_j^{(1)} =& \sum_{i} x_{i} w^{(in\rightarrow 1)}_{i\rightarrow j}\\
          S^{(1)} =& X W^{(in\rightarrow 1)}\\
          \end{align}$$
        </p>
      </div>
      <div>
        <img class="noborder" src="img/gradient-descent.gif">
      </div>
    </div>

    <aside class="notes" data-markdown>
      The linear family of algorithms are all variations on a simple premise: given an input vector, generate an output vector where every component is a weighted sum of the input vector.  This can be efficiently expressed using matrix algebra, allowing you to process multiple items at a time.

      The key then for any linear algorithm is to find the weight matrix.  This can be done analytically or using iterative methods, most notably gradient descent.
    </aside>
  </section>

  <section id="neural-network">
    <div class="tier vc">
      <svg width="450" height="500"></svg>
      <div>
        <h2 class="text-left">Neural Networks</h2>
        <ul class="boxed green stretch small">
          <li>Flexible architecture</li>
          <li>Superior accuracy</li>
          <li>Learn progressively higher-level features</li>
        </ul>
        <ul class="boxed red stretch small">
          <li>Computationally intensive</li>
          <li>Long training times</li>
        </ul>
      </div>
    </div>
<pre><code class="py" data-trim data-noescape>
from sknn.mlp import Classifier, Regressor, Layer, Convolution
layers = [Layer("Rectifier", units=100), Layer("Softmax")]
clf = Classifier(layers=layers)
</code></pre>
    <aside class="notes" data-markdown>
      Now there are many algorithms based on linear transformations, but neural networks are certainly the hottest at the moment.

      The basic neural network architecture is simply a stack of these linear transformations, except that each transformation is wrapped in a non-linear activation function.  You need that activation functions because a linear tranformation of a linear transformation is just a linear transformation (which is not very interesting or expressively powerful).

      In a neural network, the layers between the output and input are known as the hidden layers.  In theory a single hidden layer if wide enough could approximate any function, but in practice multiple hidden layers can be much more expressive.  The problem was that up until recently it was not possible to train more than a couple of layers, but now there are techniques allowing for many layers.

      Additionally, the architecture of neural networks is very flexible.  A neural network doesn't have to be a plain stack, and different kinds of layers can be used.  In particular, convolutional layers and recurrent networks are tremendously useful for certain types of problems.
    </aside>
  </section>

  <section id="deep-neural-network">
    <h2>Deep Neural Networks</h2>
    <img class="noborder" height="250px" width="auto" src="img/googlenet.png">
    <img class="noborder" height="250px" width="auto" class="fragment" src="img/datacenter.jpg">

    <aside class="notes" data-markdown>
      Which brings us to deep learning.  Those improvments in training have led to the renaissance of deep neural networks, which are setting records for processing of structured data like audio and video.  And what has been found is that every layer in a deep network is learning more abstract concepts than the layer before.  This was demonstrated most startlingly in Google's Deep Dream example, which showed that a single node could code for something as abstract as "dog".

      But deep networks are not without cost - some of these beasts are absolutely enormous.  Effective deep learning depends on massive amounts of computing power and lots of data.  This for instance is GoogLeNet: I couldn't even get the model to load without running out of GPU memory on my machine.
    </aside>
  </section>

  <section id="svm">
    <div class="tier vc">
      <div>
        <h2 class="text-left">Support Vector Machines</h2>
        <ul class="boxed green stretch small">
          <li>High quality class boundaries</li>
          <li><a href="http://jmlr.csail.mit.edu/papers/volume15/delgado14a/delgado14a.pdf">Pretty good accuracy</a></li>
          <li>One-class training!</li>
        </ul>
        <ul class="boxed red stretch small">
          <li>Lots of tuning</li>
          <li>Overfit easily</li>
          <li>Not suitable for large training sets</li>
        </ul>
      </div>
      <div>
        <img src="img/svc.gif" style="width:320px;height:auto">
        <img src="img/svc-projection.gif" style="width:320px;height:auto;clip:rect(0px,140px,140px,0px);">
      </div>
    </div>
<pre><code class="py" data-trim data-noescape>
from sklearn.svm import SVC, SVR
</code></pre>
    <aside class="notes" data-markdown>
      Although random forests and neural networks are the big performers these days, Support Vector Machines are right up there.

      Support Vector Machines exploit something known as the "kernel trick", which is a way of projecting your samples into a higher dimensional combinatorial space.  The trick is that by using certain mathematically behaved functions that work on the dot products between the sample vectors, we don't actually have to *make* the projection to solve the SVM.  The final model produced after training is based on a selection of the training samples, the so-called support vectors.  Presuming there aren't too many support vectors the function is quick to evaluate.

      Support vectors generate very high quality class boundaries and can give good accuracy in many cases.  They also can be trained on a single class for outlier detection.

      But there are big catches.  Tuning the parameters can be quite tricky, as SVMs overfit easily.  And most significantly, the memory requirements are quadratic, which can be a huge burden if you aren't careful.
    </aside>
  </section>

  <section id="new-algorithms">
    <h1>Keep your eyes open!</h1>

    <aside class="notes" data-markdown>
      The state of the art is continually being improved and new algorithms are invented all the time.  So, keep your eyes open.  Follow a machine learning blog, or use news aggregators to see what's new.  You will probably learn a thing or two.
    </aside>
  </section>

</section>

<section>
  <section id="fine-tune">
    <h1 class="text-left">5. Fine tune your best models</h1>
    <img class="noborder" height="200" width="auto" src="img/goesto11.jpg">
    <ul>
      <li>Try adding or removing features</li>
      <li>Use grid searches to fine-tune hyperparameters</li>
      <li>Train longer</li>
      <li>Make a weighted ensemble of multiple models</li>
    </ul>

    <aside class="notes" data-markdown>
      Once you have some good models, try improving them. See if adding or removing features makes a difference.  Use a grid search to optimize hyperparameters.  Maybe even make a weighted ensemble of multiple models.
    </aside>
  </section>

  <section id="bias-variance">
    <h2>The bias-variance tradeoff</h2>
    <div class="tier">
      <div>
        <svg id="bias-target" width="250" height="250">
          <g transform="translate(125, 125) scale(1.23)">
            <g class="target" stroke="black" stroke-width="0.75">
              <circle r="100" style="fill:white;"></circle>
              <circle r="90" style="fill:white;"></circle>
              <circle r="80" style="fill:gray;"></circle>
              <circle r="70" stroke="white" style="fill:gray;"></circle>
              <circle r="60" style="fill:lightblue;"></circle>
              <circle r="50" style="fill:lightblue;"></circle>
              <circle r="40" style="fill:lightcoral;"></circle>
              <circle r="30" style="fill:lightcoral;"></circle>
              <circle r="20" style="fill:yellow;"></circle>
              <circle r="10" style="fill:yellow;"></circle>
            </g>
            <g class="shots" fill="black" stroke="red" stroke-width="0.5"></g>
          </g>
        </svg>
        <h2>Bias</h2>
      </div>
      <div>
        <svg id="variance-target" width="250" height="250">
          <g transform="translate(125, 125) scale(1.23)">
            <g class="target" stroke="black" stroke-width="0.75">
              <circle r="100" style="fill:white;"></circle>
              <circle r="90" style="fill:white;"></circle>
              <circle r="80" style="fill:gray;"></circle>
              <circle r="70" stroke="white" style="fill:gray;"></circle>
              <circle r="60" style="fill:lightblue;"></circle>
              <circle r="50" style="fill:lightblue;"></circle>
              <circle r="40" style="fill:lightcoral;"></circle>
              <circle r="30" style="fill:lightcoral;"></circle>
              <circle r="20" style="fill:yellow;"></circle>
              <circle r="10" style="fill:yellow;"></circle>
            </g>
            <g class="shots" fill="black" stroke="red" stroke-width="0.5"></g>
          </g>
        </svg>
        <h2>Variance</h2>
      </div>
    </div>
    <div style="display:none">
      <span class="fragment" id="first-shots"></span>
      <span class="fragment" id="many-shots"></span>
    </div>

    <aside class="notes" data-markdown>
      The two major sources of error in models are bias and variance.  We'll use a metaphor.  **Bias** is the tendency of an model to favor specific representations of the data.  If you were shooting at a target, your bias is how far from the bullseye your shots are centered.  The counterpart of bias is **Variance**, the tendency of an algorithm to find very different representations for small variations in the data.  On a target, your variance is how spread apart your shots are.  During training, high bias leads to **Underfitting** because the algorithm is incapable of finding or building a model, while high variance leads to **Overfitting** because it effectively memorizes the training data. What we really want is a model which **Generalizes** the data and can accurately and reliably handle whatever we throw at it: a tight grouping right in the center.

      The most important point about the bias-variance tradeoff is this: it is impossible to overcome intrinsic bias in a model, but it *is* possible to overcome variance.  We will discuss some tricks for this, but the most straightforward approach is simply more training with more data on complex, low-bias models. One more reason why "big data" is a big deal.

      Which brings us to the third source of error: insufficient or unrepresentative training data.  Garbage in, garbage out.
    </aside>
  </section>

  <section id="hyperparameter-tuning">
    <h2>Tuning Hyperparameters</h2>
    <img class="noborder" src="img/validation.png">

<pre><code class="py" data-trim data-noescape>
from sklearn.grid_search import GridSearchCV,
from sklearn.cross_validation import StratifiedShuffleSplit

params = {"gamma": np.logspace(-9, 3, 13)}
splits = StratifiedShuffleSplit(y, n_iter=3, test_size=0.2)
grid = GridSearchCV(SVC(), param_grid=params, cv=splits)
grid.fit(X_train, y_train)
print grid.best_params_, grid.best_score_
</code></pre>
    <aside class="notes" data-markdown>
      The bias-variance tradeoff can be adjusted when constructing many models, by adjusting particular hyperparameters.  Choosing the right hyperparameters is very important, and can mean the difference between a model with high accuracy and one that doesn't even train.  As such, you usually need to explore variants of a model with different hyperparameters set.  Tuning hyperparameters can be tricky, as they can interact with each other or be just plain sensitive.

      Here we see an example of hyperparameter tuning for a Support Vector Machine.  The parameter is called gamma and controls how complex the model is allowed to be; we are tuning it across a logarithmic range.  So when gamma is low, the model complexity is low, and therefore the intrinisic bias of the model is high.  Both the training score and the testing score is poor: the model is underfitting.  When gamma is high, the model is allowed to be complex, which means the training score is nearly perfect but the testing score is much worse: the model is overfitting.  The sweet spot is in the middle, at 0.001.  By the way this sort of visual exploration is called a validation curve.

      Of course if when spot-checking your model you use a bad hyperparameter you might not even bother trying to improve it.  So when spot checking models like Support vector machines, do spot checks with widely spaced hyperparameters to see if any makes a difference.

      In python, one would typically use the GridSearchCV to explore a particular parameter space.  You provide the GridSearchCV with the model to tune and a dictionary of parameter options, and it will explore every combination of those options to find the one with the best accuracy.  You can then extract the parameters and retrain the model with the best ones (GridSearchCV will even do that for you).
    </aside>
  </section>

  <section id="performance-data">
    <h2>Model performance with data</h2>
    <img class="noborder" src="img/learning.png">

<pre><code class="py" data-trim data-noescape>
from sklearn.cross_validation import ShuffleSplit
from sklearn.learning_curve import learning_curve

train_sizes = np.linspace(.1, 1.0, 9)
cv = cross_validation.ShuffleSplit(
  len(y), n_iter=10, test_size=0.2)

train_sizes, train_scores, test_scores = learning_curve(
    clf, X, y, cv=cv, train_sizes=train_sizes)
</code></pre>
    <aside class="notes" data-markdown>
      Of course model performance is also heavily dependent on data.  One way to get a feel for the true intrinsic bias of a model is by looking at how well it trains with different amounts of data.  Generally you expect that your train and test accuracy will converge as you train with more and more data.  The shared asymptote of the two curves represents the intrinsic bias, the maximum possible accuracy this model can obtain.  The curve of the two lines gives you an idea about how much data you actually need to get acceptably close to that point, and thus whether the data you have is good enough.
    </aside>
  </section>

</section>

<section>
  <section id="summary">
    <h1>Put it together</h1>
    <img class="noborder" height="500px" width="auto"src="img/train.jpg">

    <aside class="notes">
      So if you follow the process, you can be produce a pretty good model with a minimum amount of effort.
    </aside>
  </section>

  <section id="results">
    <div class="tier">
      <div>
        <img class="noborder" width="auto" height="140px" src="img/forest.png">
      </div>
      <div class="w2 text-left">
        <h2>Kaggle Forest Cover Type Prediction</h2>
      </div>
    </div>
    <img class="noborder" height="500px" width="auto" src="img/forest_results.png">

    <aside class="notes">
      Just to give you a taste of how things might look after a job: here's my results for the Kaggle Forest Cover Type Prediction competition.  I'm showing test error on the y axis and training time on the y axis.  And as you can see Random Forest and Extra Trees gave the best results, and trained in relatively little time.  It wasn't even close.  If I spent more time on feature engineering, or if I trained longer and with more data I could probably do better, particularly the neural net.  But for now I we have something worth keeping.
    </aside>
  </section>

</section>

<section>
  <section id="end">
    <h2>Thank you!</h2>
    <br>
    <div class="tier">
      <div class="text-left">
        <h4>Further reading</h4>
        <ul>
          <li><a href="https://htmlpreview.github.io/?https://raw.githubusercontent.com/jmgore75/PracticalML/master/presentation/conference2015.html">Replay</a> this presentation on <a href="https://github.com/jmgore75/PracticalML/">GitHub (jmgore75/PracticalML)</a></li>
          <li><a href="http://machinelearningmastery.com/">Machine learning mastery</a> blog</li>
          <li><a href="https://www.udacity.com/course/machine-learning--ud262">Machine Learning</a> Udacity course series</li>
        </ul>
      </div>
      <div>
        <img src="img/dream_logo.jpg">
      </div>
    </div>
  </section>

  <section id="tools">
    <div class="tier">
      <div class="text-left">
        <h4>Development Tools</h4>
        <ul>
          <li><a href="https://www.python.org/">Python</a> language</li>
          <li><a href="http://scikit-learn.org">scikit-learn</a> ML library</li>
          <li><a href="https://github.com/aigamedev/scikit-neuralnetwork">scikit-neuralnetwork</a> ANN library</li>
          <li><a href="http://deeplearning.net/software/theano/">Theano</a> numerical library</li>
        </ul>
      </div>
      <div class="text-left">
        <h4>Presentation Tools</h4>
        <ul>
          <li><a href="https://github.com/hakimel/reveal.js">Reveal.js</a> presentation framework</li>
          <li><a href="http://d3js.org/">d3.js</a> charting library</li>
        </ul>
      </div>
    </div>
  </section>

</section>

</div>
</div>

<!-- Setup -->

<script src="reveal.js/lib/js/head.min.js"></script>
<script src="reveal.js/js/reveal.js"></script>

<script>
  // Full list of configuration options available at:
  // https://github.com/hakimel/reveal.js#configuration
  Reveal.initialize({
    controls: true,
    progress: true,
    history: true,
    center: true,

    transition: 'concave',

    // Optional reveal.js plugins
    dependencies: [
      { src: 'reveal.js/lib/js/classList.js', condition: function() { return !document.body.classList; } },
      { src: 'reveal.js/plugin/markdown/marked.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
      { src: 'reveal.js/plugin/markdown/markdown.js', condition: function() { return !!document.querySelector( '[data-markdown]' ); } },
      { src: 'reveal.js/plugin/math/math.js'},
      { src: 'reveal.js/plugin/highlight/highlight.js', async: true, condition: function() {
          return !!document.querySelector( 'code' );
        }, callback: function() {
          hljs.initHighlightingOnLoad();
        }
      },
      { src: 'reveal.js/plugin/zoom-js/zoom.js', async: true },
      { src: 'reveal.js/plugin/notes/notes.js', async: true }
    ]
  });
</script>

<script src="js/d3.min.js"></script>
<script src="js/dt.js"></script>
<script>
  //Animations
  (function () {
    if (!window.print_pdf) {
      var logo;
      function showLogo(event) {
        if (!logo) {
           logo = d3.select(".reveal").append("img").classed("logo", true).attr("src", "img/logo.png");
        }
        var v = event.currentSlide.id !== "title";
        logo.classed("visible", v);
      }

      Reveal.addEventListener('ready', showLogo);
      Reveal.addEventListener( 'slidechanged', showLogo);
    }

    var bias_target = new Target(d3.select("#bias-target g.shots"));
    bias_target.shooter = new Shooter(50, Math.PI*1.3, 10);

    var variance_target = new Target(d3.select("#variance-target g.shots"));
    variance_target.shooter = new Shooter(10, Math.PI*0.32, 30);

    Target.prototype.placeShots = function (shot_ids, duration) {
      var shotMap = this.shooter.shots;
      var shots = [];
      shot_ids.forEach(function (shot_id) {
        if (shotMap[shot_id]) {
          shots = shots.concat(shotMap[shot_id]);
        }
      })
      this.doShots(shots, duration);
    }

    Target.prototype.showShots = function () {
      this.doShots(this.shooter.shots["first-shots"]);
    }

    function handleChange(event) {
      var duration = event ? 1000 : 0;
      var cslide = Reveal.getCurrentSlide();
      if (cslide.id === "bias-variance") {
        var vfrag = cslide.querySelectorAll(".fragment.visible");
        var shots = [];
        for (var i = 0; i < vfrag.length; i++) {
          if (vfrag[i].id) {
            shots.push(vfrag[i].id);
          }
        }
        bias_target.placeShots(shots, duration);
        variance_target.placeShots(shots, duration);
      }
    }

    function handleSlide(event) {
      if (event.previousSlide && event.previousSlide.id === "bias-variance") {
        bias_target.showShots();
        variance_target.showShots();
      }
      if (event.currentSlide && event.currentSlide.id === "bias-variance") {
        handleChange();
      }
    }

    if (window.printing_pdf) {
      Reveal.addEventListener('ready', function () {
        bias_target.showShots();
        variance_target.showShots();
      });
    } else {
      Reveal.addEventListener('ready', handleSlide);

      Reveal.addEventListener( 'fragmentshown', handleChange);

      Reveal.addEventListener( 'fragmenthidden', handleChange);

      Reveal.addEventListener( 'slidechanged', handleSlide);
    }

    var graphMap = {
      "title" : [new Tree(5, 3, 0.1), new NN(4, 8, 8, 8, 3), new DAG(7, 3, 8), new NN(4, 32, 3)],
      "decision-tree" : [new Tree(5, 3, 0.2), new Tree(4, 3, 0), new Tree(4, 2, 0.2)],
      "random-forest" : [new Forest(4, 3, 0.1), new Forest(4, 2, 0.2), new Forest(5, 3, 0.2)],
      "neural-network"  : [new NN(4, 8, 8, 8, 3)]
    }

    function loopGraphs(slide, graphs) {
      if (!slide) {
        return;
      }
      var graphs = Array.prototype.slice.call(arguments);
      var slide = graphs.shift();

      if (!graphs.length) {
        graphs = graphMap[slide.id] || [];
      }
      var svg = d3.select(slide).select("svg");

      if (svg[0][0] && graphs.length) {
        function loop() {
          var t = svg.interrupt().transition();
          t.selectAll("*").remove();
          graphs.forEach(function (graph) {
            //Update each on a timer
            graph.steps.forEach(function (step) {
              t = t.transition().duration(step.duration || 0).each("start", function () {
                displayStep(step, svg);
              });
            });
            t = t.transition().duration(3000);
            t = t.transition().duration(clearStep.duration || 0).each("start", function () {
              displayStep(clearStep, svg);
            });
            t = t.transition().duration(500).each("start", function () {
              svg.selectAll("*").remove();
            });
          })

          t = t.each("end", function () {
            loop();
          });
        }

        loop();
      }
    }

    function showGraph(slide, graph) {
      if (!slide) {
        return;
      }
      if (!graph) {
        var graphs = graphMap[slide.id];
        if (graphs) {
          graph = graphs[0];
        }
      }
      var svg = d3.select(slide).select("svg");
      if (svg[0][0] && graph) {
        svg.interrupt().transition();
        svg.selectAll("*").remove();
        var step = graph.lastStep();
        if (step) {
          displayStep(step, svg, 0);
        }
      }
    }

    function showAllGraphs() {
      for (var id in graphMap) {
        var slide = document.getElementById(id);
        if (slide) {
          showGraph(slide);
        }
      }
    }

    if (window.printing_pdf) {
      Reveal.addEventListener('ready', function (event) {
        showAllGraphs();
      });
    } else {
      Reveal.addEventListener('ready', function (event) {
        showAllGraphs();
        loopGraphs(event.currentSlide);
      });

      Reveal.addEventListener( 'slidechanged', function(event) {
        showGraph(event.previousSlide);
        loopGraphs(event.currentSlide);
      } );
    }

  })();

</script>

</body>
</html>
